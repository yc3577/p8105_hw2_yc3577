p8105_hw2_yc3577
================
Yimeng Cai
10/01/2023

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.1     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)
library(readxl)
```

Problem 1

Step 1 clean & analyze pols-month data using read_csv to read the data,
then use separate function to separate the mon variable into day year
month. Then rename the month int data into month names. Finally use
mutate to take values of gop and dem into president. Then select related
columns and drop na.

``` r
pols_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c('year', 'month', 'day'), sep = '-') 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
month_names = 
  c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')
pols_df$month = month_names[as.integer(pols_df$month)]
pols_df = 
  mutate( pols_df,
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop"),
    year = as.integer(year)) |>
  select(-day, -starts_with("prez")) |>
  drop_na()
pols_df
```

    ## # A tibble: 822 × 9
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 Jan        23      51     253      23      45     198 dem      
    ##  2  1947 Feb        23      51     253      23      45     198 dem      
    ##  3  1947 Mar        23      51     253      23      45     198 dem      
    ##  4  1947 Apr        23      51     253      23      45     198 dem      
    ##  5  1947 May        23      51     253      23      45     198 dem      
    ##  6  1947 Jun        23      51     253      23      45     198 dem      
    ##  7  1947 Jul        23      51     253      23      45     198 dem      
    ##  8  1947 Aug        23      51     253      23      45     198 dem      
    ##  9  1947 Sep        23      51     253      23      45     198 dem      
    ## 10  1947 Oct        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

Step 2 clean & analyze snp data using read_csv to read the data, then
use separate function to separate the mon variable into day year month.
Then formulate the variable type of month day and year. Use relocate to
arrange the column in the orders of year and month. Then select related
columns and drop na.

``` r
snp_df = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c('month', 'day', 'year'), sep = '/') |>
  mutate(
    month = as.integer(month),
    day = as.integer(day),
    year = as.integer(year),
    month = month(month, label = TRUE),
    year = ifelse(year<16, year+2000, year+1900)) |>
  relocate(year, month) |>
  select(year, month, close) |>
  drop_na()
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month close
    ##    <dbl> <ord> <dbl>
    ##  1  2015 Jul   2080.
    ##  2  2015 Jun   2063.
    ##  3  2015 May   2107.
    ##  4  2015 Apr   2086.
    ##  5  2015 Mar   2068.
    ##  6  2015 Feb   2104.
    ##  7  2015 Jan   1995.
    ##  8  2014 Dec   2059.
    ##  9  2014 Nov   2068.
    ## 10  2014 Oct   2018.
    ## # ℹ 777 more rows

Step 3 clean & analyze unemployment data using read_csv to read the
data, then use separate function to separate the mon variable into day
year month. Then formulate the variable type of month day and year. Use
relocate to arrange the column in the orders of year and month. Then
select related columns and drop na.

``` r
unem_df =  
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  )|>
  mutate(
    year = as.integer(year))|>
  select(year, month, unemployment) |>
  drop_na()
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unem_df
```

    ## # A tibble: 810 × 3
    ##     year month unemployment
    ##    <int> <chr>        <dbl>
    ##  1  1948 Jan            3.4
    ##  2  1948 Feb            3.8
    ##  3  1948 Mar            4  
    ##  4  1948 Apr            3.9
    ##  5  1948 May            3.5
    ##  6  1948 Jun            3.6
    ##  7  1948 Jul            3.6
    ##  8  1948 Aug            3.9
    ##  9  1948 Sep            3.8
    ## 10  1948 Oct            3.7
    ## # ℹ 800 more rows

``` r
combined_df1 =
  left_join(pols_df, snp_df)|>
  left_join(x = _, y = unem_df)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
combined_df1
```

    ## # A tibble: 822 × 11
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 Jan        23      51     253      23      45     198 dem          NA
    ##  2  1947 Feb        23      51     253      23      45     198 dem          NA
    ##  3  1947 Mar        23      51     253      23      45     198 dem          NA
    ##  4  1947 Apr        23      51     253      23      45     198 dem          NA
    ##  5  1947 May        23      51     253      23      45     198 dem          NA
    ##  6  1947 Jun        23      51     253      23      45     198 dem          NA
    ##  7  1947 Jul        23      51     253      23      45     198 dem          NA
    ##  8  1947 Aug        23      51     253      23      45     198 dem          NA
    ##  9  1947 Sep        23      51     253      23      45     198 dem          NA
    ## 10  1947 Oct        23      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

Problem 2

Step 1 Clean and read Mytrash data using `read_excel` and `clean_names`.
Then use `mutate` to calculate homes_powered by inputting the function
`(weight_tons*500)/30`. Use `add_column(type = "Mytrash")` to add
additional variable to dataset for later combining usage. Finally drop
NA data in dumpster with `drop_na(starts_with("dumpster"))`.

``` r
Mrtrash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N587") |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30) |>
  add_column(type = "Mrtrash")|>
  drop_na(starts_with("dumpster"))
Mrtrash_df
```

    ## # A tibble: 584 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, type <chr>

Step 2 Clean and read Proftrash data using `read_excel` and
`clean_names`. Then use `mutate` to calculate homes_powered by inputting
the function `(weight_tons*500)/30`. Then formulate the year column into
character with `as.character(year)`. Use
`add_column(type = "Proftrash")` to add additional variable to dataset
for later combining usage. Finally drop NA data in dumpster with
`drop_na(starts_with("dumpster"))`.

``` r
Proftrash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 2) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.character(year))|>
  add_column(type = "Proftrash")|>
  drop_na(starts_with("dumpster"))

Proftrash_df
```

    ## # A tibble: 106 × 14
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ##  4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ##  5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ##  6        6 March    2017  2017-03-30 00:00:00        1.71                 15
    ##  7        7 April    2017  2017-04-01 00:00:00        1.82                 15
    ##  8        8 April    2017  2017-04-20 00:00:00        2.37                 15
    ##  9        9 May      2017  2017-05-10 00:00:00        2.64                 15
    ## 10       10 May      2017  2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, type <chr>

Step 3 Clean and read Gwytrash data using `read_excel` and
`clean_names`. Then use `mutate` to calculate homes_powered by inputting
the function `(weight_tons*500)/30`. Then formulate the year column into
character with `as.character(year)`. Use `add_column(type = "Gwytrash")`
to add additional variable to dataset for later combining usage. Finally
drop NA data in dumpster with `drop_na(starts_with("dumpster"))`.

``` r
Gwytrash_df = 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 4) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = (weight_tons*500)/30,
    year = as.character(year))|>
  add_column(type = "Gwytrash")|>
  drop_na(starts_with("dumpster"))

Gwytrash_df
```

    ## # A tibble: 155 × 13
    ##    dumpster month  year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July   2021  2021-07-03 00:00:00        0.93                 15
    ##  2        2 July   2021  2021-07-07 00:00:00        2.26                 15
    ##  3        3 July   2021  2021-07-07 00:00:00        1.62                 15
    ##  4        4 July   2021  2021-07-16 00:00:00        1.76                 15
    ##  5        5 July   2021  2021-07-30 00:00:00        1.53                 15
    ##  6        6 August 2021  2021-08-11 00:00:00        2.06                 15
    ##  7        7 August 2021  2021-08-14 00:00:00        1.9                  15
    ##  8        8 August 2021  2021-08-16 00:00:00        2.16                 15
    ##  9        9 August 2021  2021-08-16 00:00:00        2.6                  15
    ## 10       10 August 2021  2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, type <chr>

Step 4 Combine `Mytrash_df`, `Proftrash_df` using 1st `bind_rows`. Then
combine binded dataframe with `Gwytrash_df` using 2nd `bind_rows`.

``` r
combine_df2 = 
  bind_rows(Mrtrash_df, Proftrash_df) |>
  bind_rows(x = _, y = Gwytrash_df)
combine_df2
```

    ## # A tibble: 845 × 15
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, type <chr>

Problem 3

Step 1 Read and Clean the `MCI_baseline.csv` of baseline data using
`read_csv` and then use `janitor::clean_names()` to clean the variable
names. During table reading, we need to skip the 1st row with
`skip = 1`. Then we need to mutate the variable of sex and apoe4 with
`mutate(sex = recode( sex = recode(sex, "0" = "F", "1" = "M"), apoe4 = recode(apoe4, "0" = "apoe4_noncarrier", "1" = "apoe4_carrier")`
to make sure sex and apoe4 are appropriately encoded into character
format, and change the ‘.’ into ‘NA’ by
`age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset)` for later
fileter steps. Finally, we need to use filter of
`filter(current_age < age_at_onset | is.na(age_at_onset))` to remove any
participants who do not meet the stated inclusion criteria.

``` r
base_df = 
  read_csv("/Users/christinecym/Desktop/R data/P8105/HW/P8105_hw2_yc3577/data_mci/MCI_baseline.csv", skip =1) |>
  janitor::clean_names()|>
  mutate(
    sex = recode(sex, "0" = "F", "1" = "M"),
    apoe4 = recode(apoe4, "0" = "apoe4_noncarrier", "1" = "apoe4_carrier"),
    age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset)
    )|>
  filter(current_age < age_at_onset | is.na(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
base_df
```

    ## # A tibble: 479 × 6
    ##       id current_age sex   education apoe4            age_at_onset
    ##    <dbl>       <dbl> <chr>     <dbl> <chr>            <chr>       
    ##  1     1        63.1 F            16 apoe4_carrier    <NA>        
    ##  2     2        65.6 F            20 apoe4_carrier    <NA>        
    ##  3     3        62.5 M            16 apoe4_carrier    66.8        
    ##  4     4        69.8 F            16 apoe4_noncarrier <NA>        
    ##  5     5        66   M            16 apoe4_noncarrier 68.7        
    ##  6     6        62.5 M            16 apoe4_noncarrier <NA>        
    ##  7     7        66.5 M            18 apoe4_noncarrier 74          
    ##  8     8        67.2 F            18 apoe4_noncarrier <NA>        
    ##  9     9        66.7 F            16 apoe4_noncarrier <NA>        
    ## 10    10        64.1 F            18 apoe4_noncarrier <NA>        
    ## # ℹ 469 more rows

Step 2 Read and Clean the `mci_amyloid.csv` of biomarkers using
`read_csv` and then use `janitor::clean_names()` to clean the variable
names. During table reading, we need to skip the 1st row with
`skip = 1`. Then we need to rename the variable name with
`rename(id = ..., time_0 = ...)` to make sure we have a common name id,
and same format of time_X by change baseline to the time_0. Finally, we
need to use `pivot_longer(time0:time8, names_to = ..., values_to = ...)`
to make a tidy table with a column named `"period_time"` that includes
all the time_period into one column as a new variable. Then finally drop
na data with `drop_na()`.

``` r
amy_df = 
  read_csv("/Users/christinecym/Desktop/R data/P8105/HW/P8105_hw2_yc3577/data_mci/mci_amyloid.csv", skip =1) |>
  janitor::clean_names() |>
  rename(
    id = study_id,
    time_0 = baseline
  )|>
  pivot_longer(
    time_0:time_8,
    names_to = "period_time",
    values_to = "year") |>
  drop_na()
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
amy_df
```

    ## # A tibble: 2,272 × 3
    ##       id period_time year       
    ##    <dbl> <chr>       <chr>      
    ##  1     1 time_0      0.1105487  
    ##  2     1 time_4      0.109325197
    ##  3     1 time_6      0.104756131
    ##  4     1 time_8      0.107257697
    ##  5     2 time_0      0.107481183
    ##  6     2 time_2      0.109157373
    ##  7     2 time_4      0.109457839
    ##  8     2 time_6      0.105729713
    ##  9     2 time_8      0.10661845 
    ## 10     3 time_0      0.106087034
    ## # ℹ 2,262 more rows

Step 3 Combine two tables use `anti_join(base_df, amy_df)` based on the
common ID, since we need to find the only participants in each datasets.
We need to use anti_join twice to find each differences.
(`anti_join(amy_df, base_df)`). Then we need to use
`inner_join(base_df, amy_df)` base on the common ID to find the
participants in both datasets.

``` r
combine_df3 =
  anti_join(base_df, amy_df)
```

    ## Joining with `by = join_by(id)`

``` r
combine_df3
```

    ## # A tibble: 8 × 6
    ##      id current_age sex   education apoe4            age_at_onset
    ##   <dbl>       <dbl> <chr>     <dbl> <chr>            <chr>       
    ## 1    14        58.4 F            20 apoe4_noncarrier 66.2        
    ## 2    49        64.7 M            16 apoe4_noncarrier 68.4        
    ## 3    92        68.6 F            20 apoe4_noncarrier <NA>        
    ## 4   179        68.1 M            16 apoe4_noncarrier <NA>        
    ## 5   268        61.4 F            18 apoe4_carrier    67.5        
    ## 6   304        63.8 F            16 apoe4_noncarrier <NA>        
    ## 7   389        59.3 F            16 apoe4_noncarrier <NA>        
    ## 8   412        67   M            16 apoe4_carrier    <NA>

``` r
combine_df4 = 
  anti_join(amy_df, base_df)
```

    ## Joining with `by = join_by(id)`

``` r
combine_df4
```

    ## # A tibble: 76 × 3
    ##       id period_time year       
    ##    <dbl> <chr>       <chr>      
    ##  1    72 time_0      0.106965463
    ##  2    72 time_4      0.107266218
    ##  3    72 time_6      0.106665207
    ##  4   234 time_0      0.110521689
    ##  5   234 time_2      0.110988335
    ##  6   234 time_4      0.110318671
    ##  7   234 time_6      0.107334344
    ##  8   234 time_8      0.108868811
    ##  9   283 time_0      0.113436336
    ## 10   283 time_2      0.106568976
    ## # ℹ 66 more rows

``` r
combine_df5 =
  inner_join(base_df, amy_df)
```

    ## Joining with `by = join_by(id)`

``` r
combine_df5
```

    ## # A tibble: 2,196 × 8
    ##       id current_age sex   education apoe4        age_at_onset period_time year 
    ##    <dbl>       <dbl> <chr>     <dbl> <chr>        <chr>        <chr>       <chr>
    ##  1     1        63.1 F            16 apoe4_carri… <NA>         time_0      0.11…
    ##  2     1        63.1 F            16 apoe4_carri… <NA>         time_4      0.10…
    ##  3     1        63.1 F            16 apoe4_carri… <NA>         time_6      0.10…
    ##  4     1        63.1 F            16 apoe4_carri… <NA>         time_8      0.10…
    ##  5     2        65.6 F            20 apoe4_carri… <NA>         time_0      0.10…
    ##  6     2        65.6 F            20 apoe4_carri… <NA>         time_2      0.10…
    ##  7     2        65.6 F            20 apoe4_carri… <NA>         time_4      0.10…
    ##  8     2        65.6 F            20 apoe4_carri… <NA>         time_6      0.10…
    ##  9     2        65.6 F            20 apoe4_carri… <NA>         time_8      0.10…
    ## 10     3        62.5 M            16 apoe4_carri… 66.8         time_0      0.10…
    ## # ℹ 2,186 more rows
